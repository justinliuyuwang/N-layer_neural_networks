{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Justin Wang December 2020\n",
    "\n",
    "This script will perform logistic regression (forward and backprop using vectorization).\n",
    "\n",
    "First, we establish the correct project (and associated info) and import the related datasets for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import scipy\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "import os\n",
    "import PIL\n",
    "from matplotlib import pyplot\n",
    "import random\n",
    "\n",
    "#project = \"RashData\"\n",
    "#positive = \"Lyme_Positive\"\n",
    "#negative = \"Lyme_Negative\"\n",
    "\n",
    "#project = \"chest_xray\"\n",
    "#positive = \"NORMAL\"\n",
    "#negative = \"PNEUMONIA\"\n",
    "\n",
    "#project = \"chest_covid\"\n",
    "#positive = \"NORMAL\"\n",
    "#negative = [\"COVID19\",\"PNEUMONIA\"]\n",
    "#need a code for splitting the negative dataset\n",
    "\n",
    "project = \"cat_dog\"\n",
    "positive = \"cats\"\n",
    "negative = \"dogs\"\n",
    "\n",
    "#import datasets    \n",
    "f = h5py.File(project+'.hdf5', \"r\")\n",
    "\n",
    "train_pos_dset = f['train/'+positive]\n",
    "train_neg_dset = f['train/'+negative]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we establish some basic information about the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_info(train_pos_dset, train_neg_dset):\n",
    "    #number of training examples for each class\n",
    "    num_train_neg = train_pos_dset.shape[0]\n",
    "    num_train_pos = train_neg_dset.shape[0]\n",
    "\n",
    "    num_features = train_pos_dset.shape[1]\n",
    "\n",
    "    #list of indices for accessing images from the datasets\n",
    "    train_neg_index_list = list(range(num_train_neg))\n",
    "    train_pos_index_list = list(range(num_train_pos))\n",
    "    \n",
    "    return num_train_neg, num_train_pos, num_features, train_neg_index_list, train_pos_index_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the meat of the code, in which we iterate through epochs and iterate through mini-batches within each epoch. Forward and back propagation (a step of gradient descent) is completed once for each mini-batch. Minibatches are shuffled and newly generated for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(layers, num_features):\n",
    "    #layers is a list describing the number of nodes in each layer, including the output layer but not the features (i.e layers=[5,2,3,1] has 5 nodes in layer 1, 2 nodes in layer 2.... 1 node in the output layer)\n",
    "    \n",
    "    W = []\n",
    "    B = []    \n",
    "    #W and B are lists containing weights and biases matrices - the i'th item in W is the i'th set of weights (i.e the second item in W is the matrix of weights between the first and second hidden layers)\n",
    "    \n",
    "    x = 0\n",
    "    \n",
    "    #TODO: check if these initializations are appropriate\n",
    "    while x < len(layers):\n",
    "        if x == 0:\n",
    "            W.append(np.random.rand(layers[x],num_features))\n",
    "        else:\n",
    "            W.append(np.random.rand(layers[x],layers[x-1]))\n",
    "            \n",
    "        B.append(np.zeroes(layers[x],1))\n",
    "        x+=1\n",
    "            \n",
    "    parameters = {\"W\":W,\n",
    "                  \"B\":B}\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_batch(train_neg_index_list,train_pos_index_list,mini_batch_size)\n",
    "    #list of indices for a given mini-batch (used to access the images for this mini-batch from the dataset)\n",
    "    pos_mini_batches = []\n",
    "    neg_mini_batches = []\n",
    "\n",
    "        \n",
    "    num_instances_batched=0\n",
    "\n",
    "    #iterate through and add all the mini batches for this epoch to the collector lists pos_mini_batches & neg_mini_batches\n",
    "    #(only making sure we get all the positive instances.. we don't need to iterate through ALL negative examples if theres a mismatch between # pos and # neg)\n",
    "    while num_instances_batched < num_train_pos:\n",
    "\n",
    "\n",
    "        #slice locations on shuffled index list (indicates which shuffled indices are associated with this current mini-batch)\n",
    "        #this slice should cover half a batch's worth of indices since we're splitting the classes 50-50\n",
    "        slice_start_neg = int(num_instances_batched%num_train_neg)\n",
    "        slice_end_neg = int((num_instances_batched+mini_batch_size/2)%num_train_neg)\n",
    "\n",
    "\n",
    "        #NOTE: we grab from the first few indices (wraparound) if we have to loop around/duplicate instances to complete batches... this is same as grabbing randoms to fill in because the list is randomized\n",
    "        #if we don't have a wrap-around\n",
    "        if slice_end_neg > slice_start_neg:\n",
    "            neg_mini_batches.append(train_neg_index_list[slice_start_neg:slice_end_neg]) \n",
    "        #if we have a wrap-around\n",
    "        else:\n",
    "            neg_mini_batches.append(train_neg_index_list[slice_start_neg:] + train_neg_index_list[:slice_end_neg]) \n",
    "\n",
    "\n",
    "\n",
    "        #repeat for positive class\n",
    "        slice_start_pos = int(num_instances_batched%num_train_pos)\n",
    "        slice_end_pos = int((num_instances_batched+mini_batch_size/2)%num_train_pos)\n",
    "\n",
    "\n",
    "        if slice_end_pos > slice_start_pos:\n",
    "            pos_mini_batches.append(train_pos_index_list[slice_start_pos:slice_end_pos])\n",
    "        else:\n",
    "            pos_mini_batches.append(train_pos_index_list[slice_start_pos:] + train_pos_index_list[:slice_end_pos]) \n",
    "\n",
    "\n",
    "\n",
    "        #iterate to next mini-batch\n",
    "        num_instances_batched+=mini_batch_size/2\n",
    "        \n",
    "        \n",
    "            \n",
    "    return neg_mini_batches, pos_mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_label(neg_indices, pos_indices, train_neg_dset, train_pos_dset, mini_batch_size, num_features):\n",
    "    #matrices containing our features and their labels\n",
    "            \n",
    "    \n",
    "    #(m,n[0])\n",
    "    features = np.empty([mini_batch_size,num_features])    \n",
    "\n",
    "    #(1,m) ... will transpose upon return\n",
    "    labels = np.empty([mini_batch_size,1])                       \n",
    "    \n",
    "    counter = 0\n",
    "\n",
    "    #fancy indexing? super slow - 10-20x slower because sorting of indices is needed\n",
    "    #extract the dataset images pointed to by the current minibatch, combining both negative and positive classes\n",
    "    for index in neg_indices:\n",
    "        features[counter] = train_neg_dset[index]\n",
    "\n",
    "        labels[counter] = 0\n",
    "        counter+=1\n",
    "\n",
    "\n",
    "    for index in pos_indices:\n",
    "        features[counter] = train_pos_dset[index]\n",
    "\n",
    "        labels[counter] = 1\n",
    "        counter+=1  \n",
    "            \n",
    "    if counter not == mini_batch_size:\n",
    "        print(\"error: batch size - mini batch indices mismatch\")\n",
    "    \n",
    "    return features, labels.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop():\n",
    "    \n",
    "    #TODO: variable g(Z) setting/matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_prop():\n",
    "    \n",
    "#TODO: variable g(Z) setting/matrix    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(parameters, features, labels, num_features, learning_rate):\n",
    "        \n",
    "       \n",
    "    \n",
    "\n",
    "    #start code here\n",
    "        \n",
    "            \n",
    "            \n",
    "        ####\n",
    "        # SHALLOW NEURAL NETWORK - SPECIFIC CODE STARTS HERE\n",
    "        ####\n",
    "        #\n",
    "        # \n",
    "        # FORWARD AND BACKPROP CODE HERE\n",
    "        # Z = WT X + b\n",
    "\n",
    "        Z = np.empty([1,mini_batch_size])\n",
    "        Z = W.transpose\n",
    "        # A = sigmoid(Z)\n",
    "        # dZ = A-Y\n",
    "        # dw = 1/m XdZT\n",
    "        # db = 1/m np.sum(dZ)\n",
    "        # w:= w- alphadw\n",
    "        # b:= b - alphadb\n",
    "        #\n",
    "        #\n",
    "        ####\n",
    "        # SHALLOW NEURAL NETWORK - SPECIFIC CODE ENDS HERE\n",
    "        ####\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "def model(train_pos_dset, train_neg_dset, val_pos_dset, val_neg_dset, mini_batch_size =32, layers = [1], epochs = 1000, print_cost=False, learning_rate=0.005):\n",
    "\n",
    "    num_train_neg, num_train_pos, num_features, train_neg_index_list, train_pos_index_list = training_info(train_pos_dset, train_neg_dset)\n",
    "    \n",
    "    parameters = intialize(layers, num_features)\n",
    "    \n",
    "    #iterate through all the epochs\n",
    "    while epoch>0:\n",
    "\n",
    "        #shuffle the lists of indices, effectively shuffling the training instances among the mini-batches \n",
    "        random.shuffle(train_neg_index_list)\n",
    "        random.shuffle(train_pos_index_list)\n",
    "        \n",
    "        #neg_mini_batches and pos_mini_batches are lists of lists of indices pointing to training instances\n",
    "        neg_mini_batches, pos_mini_batches = mini_batch(train_neg_index_list,train_pos_index_list,mini_batch_size)\n",
    "        \n",
    "        #iterate through all the mini-batches (e.g. neg_indices contains the indices of a single mini-batch of negative class training instances)\n",
    "        for neg_indices, pos_indices in zip(neg_mini_batches, pos_mini_batches):\n",
    "            \n",
    "            #extract feature list and label list from this mini-batch\n",
    "            features, labels = feature_label(neg_indices, pos_indices,train_neg_dset, train_pos_dset, mini_batch_size, num_features)\n",
    "            parameters = gradient_descent(parameters, features, labels, num_features, learning_rate)\n",
    "        \n",
    "            #maybe also write code for printing cost\n",
    "             #maybe write code for % success at test & val\n",
    "                \n",
    "        #TODO write code for printing cost\n",
    "        #maybe write code for % success at test & val\n",
    "    \n",
    "        #iterate to next epoch\n",
    "        epoch-=1\n",
    "        \n",
    "    return parameters\n",
    "    #TODO write code for % success at test & val, cost using prediction()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(test_or_val = \"val\", val_or_test_neg_dset, val_or_test_pos_dset):\n",
    "    #likely calls model() for parameters\n",
    "    #likely uses forward_prop() for finding y-hat\n",
    "    \n",
    "    #print parameters or log externally\n",
    "    #TODO write code for eval % for val or test if exists\n",
    "    \n",
    "    \n",
    "def accuracy(test_or_val = \"val\", predictions,val_or_test_neg_dset,val_or_test_pos_dset,show_wrong=3):\n",
    "    #TODO show accuracy and images that are incorrectly classified - default 3 from each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
